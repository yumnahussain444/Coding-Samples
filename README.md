# Data Processing and Research Coding Portfolio

This repository contains end-to-end data tasks and research pipelines in Stata and Python. The projects focus on cleaning messy data, merging across sources, extracting structured information from text, and producing analysis-ready outputs (tables and figures).

## Skills shown across projects
- Data cleaning and quality checks (missingness, duplicates, outliers, sanity checks)
- Merging and record linkage (title standardization, match audits, matched versus unmatched outputs)
- Text processing and natural language processing (markup-to-text conversion, tokenization, sentence segmentation, parsing noisy tags)
- Rule-based text classification (dictionary-based genre categorization)
- Visualization and summaries (time-series plots, ranked distributions, heatmaps, summary tables)
- Reproducible workflows (modular scripts, clear inputs and outputs, consistent file naming)

## Projects
- Court opinion parsing and descriptive summaries (LexisNexis text exports)
- Ten-Q filing retrieval with word and sentence counts plus diluted earnings-per-share extraction (United States Securities and Exchange Commission public filings)
- Linking banned book records to crowdsourced genre tags (Goodreads tags + PEN America banned book dataset)
- Firm financial metrics and macroeconomic merge with country plots 
- Survey analysis of emotional change and belief statements (descriptive statistics, regression, basic text analysis)

## How to run
Each project folder includes a project-specific README with:
- required input files
- script order (if multiple scripts)
- outputs written by the pipeline

## Contact
Yumna Hussain â€” yumnahussain444@gmail.com
